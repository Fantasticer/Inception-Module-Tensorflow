{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inception Train and Test\n",
    "\n",
    "This notebook uses the inception module implemented in `inception_layer.py`.\n",
    "\n",
    "The dataset used is the MNIST dataset. The MNIST database of handwritten digits has a training set of 60,000 examples, and a test set of 10,000 examples.\n",
    "\n",
    "A modified architecture of the GoogLeNet has been used to account for the smaller dimensions of images (28x28) and resource limitations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohit/virtualenvs/tensorflow/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from layers.fc_layer import fc_layer\n",
    "from layers.max_pool import max_pool\n",
    "from layers.conv_layer import conv_layer\n",
    "from inception_layer import inception_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating placeholders\n",
    "x = tf.placeholder(tf.float32, shape = [None, 784])\n",
    "y_true = tf.placeholder(tf.float32, shape = [None, 10])\n",
    "hold_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_image = tf.reshape(x, [-1, 28, 28, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Architecture\n",
    "\n",
    "The architecture of the *InceptionNet* in this notebook is loosely based on the GoogLeNet architecture. The layers `inception2a` and `inception2b` are taken from the **inception3a** and **inception3b** layers respectively of GoogLeNet. Similarily, `inception3a` and `inception3b` are based on the **inception4a** and **inception4b** layers of GoogLeNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the network\n",
    "conv1 = conv_layer(x_image, filter_height = 5, filter_width=5, num_filters=64, stride=1,name='conv1')\n",
    "pool1 = max_pool(conv1, name='pool1')\n",
    "\n",
    "inception2a = inception_layer(pool1, 64, 96, 128, 16, 32, 32, name = 'inception1a')\n",
    "inception2b = inception_layer(inception2a, 128, 128, 192, 32, 96, 64, name = 'inception1b')\n",
    "pool2 = max_pool(inception2b, name = 'pool2')\n",
    "\n",
    "inception3a = inception_layer(pool2, 192, 96, 208, 16, 48, 64, name = 'inception3a')\n",
    "inception3b = inception_layer(inception3a, 160, 112, 224, 24, 64, 64, name = 'inception3b')\n",
    "\n",
    "gap = tf.nn.avg_pool(inception3b, ksize = [1, 6, 6, 1], strides = [1, 1, 1, 1], padding = 'VALID', name = 'gap')\n",
    "gap_dropout = tf.nn.dropout(gap, keep_prob = hold_prob)\n",
    "\n",
    "flatten = tf.contrib.layers.flatten(gap_dropout)\n",
    "fc4 = fc_layer(flatten, input_size = int(flatten.get_shape()[-1]), output_size = 10, relu = False, name = 'fc4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Function\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels = y_true, logits = fc4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = 0.001)\n",
    "train = optimizer.minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# To measure accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(fc4, 1), tf.argmax(y_true, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 0 epochs, training accuracy 0.0859375           test accuracy 0.099\n",
      "after 1 epochs, training accuracy 0.96875           test accuracy 0.916\n",
      "after 2 epochs, training accuracy 0.984375           test accuracy 0.961\n",
      "after 3 epochs, training accuracy 0.96875           test accuracy 0.975\n",
      "after 4 epochs, training accuracy 0.976562           test accuracy 0.98\n",
      "after 5 epochs, training accuracy 0.992188           test accuracy 0.986\n",
      "after 6 epochs, training accuracy 0.960938           test accuracy 0.991\n",
      "after 7 epochs, training accuracy 0.984375           test accuracy 0.984\n",
      "after 8 epochs, training accuracy 0.992188           test accuracy 0.992\n",
      "after 9 epochs, training accuracy 1           test accuracy 0.983\n",
      "after 10 epochs, training accuracy 0.992188           test accuracy 0.99\n"
     ]
    }
   ],
   "source": [
    "steps = 5001\n",
    "batch_size = 128\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(init)\n",
    "    \n",
    "    for i in range(steps):\n",
    "        \n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        \n",
    "        if i % 500 == 0:\n",
    "            \n",
    "                train_accuracy = accuracy.eval(feed_dict={x: batch_x, y_true: batch_y, hold_prob : 1.0})\n",
    "                test_accuracy = accuracy.eval(feed_dict = {x : mnist.test.images[: 1000], \n",
    "                                                           y_true : mnist.test.labels[: 1000], hold_prob : 1.0})\n",
    "                \n",
    "                print('after %d epochs, training accuracy %g           test accuracy %g'\\\n",
    "                      % (i//500, train_accuracy, test_accuracy)) \n",
    "                \n",
    "        sess.run(train, feed_dict = {x : batch_x, y_true : batch_y, hold_prob : 0.4})\n",
    "                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
